\documentclass[officiallayout]{tktla}

\usepackage[utf8]{inputenc}
\usepackage[T1]{fontenc}

\usepackage{graphicx}
\usepackage{url}
\usepackage{longtable}

\usepackage{amsmath}
\usepackage{amssymb}
\usepackage{amsfonts}
\usepackage{amsthm}


\title{Compressed Full-Text Indexes for Highly Repetitive Collections}
\author{Jouni Sirén}
\authorcontact{jouni.siren@cs.helsinki.fi\par
  http://www.cs.helsinki.fi/jouni.siren/}
\pubtime{June}{2012}
\reportno{5}
\isbnpaperback{978-952-10-8051-7}
\isbnpdf{978-952-10-8052-4}
\issn{1238-8645}
\printhouse{Unigrafia}
\pubpages{97 + 63}
\supervisorlist{Veli Mäkinen, University of Helsinki, Finland}
\preexaminera{Kunihiko Sadakane, National Institute of Informatics, Japan}
\preexaminerb{Jorma Tarhio, Aalto University, Finland}
\opponent{Giovanni Manzini, University of Eastern Piedmont, Italy}
\custos{Veli Mäkinen, University of Helsinki, Finland}
\generalterms{data structures, data compression}
\additionalkeywords{compressed data structures, full-text indexes, string processing, suffix array, Burrows-Wheeler transform, highly repetitive collections}
\crcshort{E.1, E.4, H.3}
\crclong{
\item[E.1] [Data Structures]: String data structures
\item[E.4] [Coding and Information Theory]: Data compaction and compression --- compressed data structures
\item[H.3.3] [Information Storage and Retrieval]: Information search and retrieval --- full-text indexes
}
\permissionnotice{
To be presented, with the permission of the Faculty of Science of the University of Helsinki, for public criticism, in Auditorium XII, University Main Building, on June 29th, 2012, at 12 o'clock noon.
}


% Various definition
\newtheorem{theorem}{Theorem}[chapter]
\newtheorem{lemma}{Lemma}[chapter]
\newtheorem{corollary}{Corollary}[chapter]
\theoremstyle{definition}
\newtheorem{definition}{Definition}[chapter]
\theoremstyle{remark}
\newtheorem{claim}{Claim}[chapter]

\newcommand{\SA}{\ensuremath{\mathsf{SA}}}
\newcommand{\CSA}{\ensuremath{\mathsf{CSA}}}
\newcommand{\RA}{\ensuremath{\mathsf{RA}}}
\newcommand{\BWT}{\ensuremath{\mathsf{BWT}}}
\newcommand{\LCP}{\ensuremath{\mathsf{LCP}}}
\newcommand{\PLCP}{\ensuremath{\mathsf{PLCP}}}
\newcommand{\Path}{\ensuremath{\mathsf{P}}}
\newcommand{\from}{\ensuremath{\mathit{from}}}
\newcommand{\myleft}{\ensuremath{\mathit{left}}}

\newcommand{\set}[1]{\ensuremath{\{ #1 \}}}
\newcommand{\Exp}[1]{\ensuremath{\mathrm{E}\left[ #1 \right]}}
\newcommand{\abs}[1]{\ensuremath{\lvert #1 \rvert}}

\newcommand{\orderk}[1]{order\nobreakdash-$#1$}
\newcommand{\Orderk}[1]{Order\nobreakdash-$#1$}
\newcommand{\LF}{$LF$\nobreakdash-mapping}
\newcommand{\gammacode}{$\gamma$\nobreakdash-code}
\newcommand{\deltacode}{$\delta$\nobreakdash-code}
\newcommand{\onebit}{$1$\nobreakdash-bit}
\newcommand{\zerobit}{$0$\nobreakdash-bit}

\newcommand{\lzindex}{LZ\nobreakdash-index}
\newcommand{\sadcsa}{Sad\nobreakdash-CSA}
\newcommand{\ssarrr}{SSA\nobreakdash-RRR}

\newcommand{\find}{\emph{find}}
\newcommand{\locate}{\emph{locate}}
\newcommand{\extract}{\emph{extract}}
\newcommand{\rank}{\emph{rank}}
\newcommand{\select}{\emph{select}}

\DeclareMathOperator{\mrank}{rank}
\DeclareMathOperator{\mselect}{select}
\DeclareMathOperator{\mchar}{char}
\DeclareMathOperator{\lcp}{lcp}
\DeclareMathOperator{\popcount}{popcount}

\DeclareMathOperator{\run}{run}
\DeclareMathOperator{\gap}{gap}

\newcommand{\etal}[1]{et~al.~\cite{#1}}


\begin{document}

\frontmatter

\maketitle

\begin{abstract}
This thesis studies problems related to compressed full-text indexes. A full-text index is a data structure for indexing textual (sequence) data, so that the occurrences of any query string in the data can be found efficiently. While most full-text indexes require much more space than the sequences they index, recent compressed indexes have overcome this limitation. These compressed indexes combine a compressed representation of the index with some extra information that allows decompressing any part of the data efficiently. This way, they provide similar functionality as the uncompressed indexes, while using only slightly more space than the compressed data.

The efficiency of data compression is usually measured in terms of entropy. While entropy-based estimates predict the compressed size of most texts accurately, they fail with highly repetitive collections of texts. Examples of such collections include different versions of a document and the genomes of a number of individuals from the same population. While the entropy of a highly repetitive collection is usually similar to that of a text of the same kind, the collection can often be compressed much better than the entropy-based estimate.

Most compressed full-text indexes are based on the Burrows-Wheeler transform (BWT). Originally intended for data compression, the BWT has deep connections with full-text indexes such as the suffix tree and the suffix array. With some additional information, these indexes can be simulated with the Burrows-Wheeler transform. The first contribution of this thesis is the first BWT-based index that can compress highly repetitive collections efficiently.

Compressed indexes allow us to handle much larger data sets than the corresponding uncompressed indexes. To take full advantage of this, we need algorithms for constructing the compressed index directly, instead of first constructing an uncompressed index and then compressing it. The second contribution of this thesis is an algorithm for merging the BWT-based indexes of two text collections. By using this algorithm, we can derive better space-efficient construction algorithms for BWT-based indexes.

The basic BWT-based indexes provide similar functionality as the suffix array. With some additional structures, the functionality can be extended to that of the suffix tree. One of the structures is an array storing the lengths of the longest common prefixes of lexicographically adjacent suffixes of the text. The third contribution of this thesis is a space-efficient algorithm for constructing this array, and a new compressed representation of the array.

In the case of individual genomes, the highly repetitive collection can be considered a sample from a larger collection. This collection consists of a reference sequence and a set of possible differences from the reference, so that each sequence contains a subset of the differences. The fourth contribution of this thesis is a BWT-based index that extrapolates the larger collection from the sample and indexes it.
\end{abstract}


\begin{acknowledgements}
I thank my supervisor Veli Mäkinen for the support and guidance. I also thank my coauthors Diego Arroyuelo, Francisco Claude, Paolo Ferragina, Sebastian Maneth, Gonzalo Navarro, Kim Nguyen, Rossano Venturini, and Niko Välimäki for the fruitful collaboration. In addition to these people, Travis Gagie, Riku Katainen, Serikzhan Kazi, Juha Kärkkäinen, Simon Puglisi, Giovanna Rosone, Leena Salmela, and the numerous anonymous referees deserve thanks for the ideas, advice, and feedback.

Special thanks go to the IT team of the Department of Computer Science, and especially to Jani Jaakkola, for the excellent IT infrastructure and the helpful support well beyond normal working hours.

During the course of my doctoral studies, I was affiliated with the Department of Computer Science at the University of Helsinki, Helsinki Institute for Information Technology (HIIT), Helsinki Doctoral School in Computer Science and Engineering (Hecse), Graduate School in Computational Biology, Bioinformatics, and Biometrics (ComBi), Finnish Doctoral Programme in Computational Sciences (FICS), Finnish Centre of Excellence for Algorithmic Data Analysis Research (Algodan), and Finnish Centre of Excellence in Cancer Genetics Research. My work was also partially funded by the Academy of Finland, the Research Foundation of the University of Helsinki, and the Nokia Foundation.

Finally, I would like to thank the Student Union of the University of Helsinki, the numerous other student organizations at the University, and Ropecon for all these years. Without these organizations and the fascinating people in them, I would have finished my studies much, much faster.
\end{acknowledgements}


\chapter*{Original Papers}

This thesis consists of an introduction and the following peer-reviewed publications, which are referred to as Papers I--IV in the text. These publications are reproduced at the end of the thesis.

\renewcommand{\theenumi}{\Roman{enumi}.}
\renewcommand{\labelenumi}{\theenumi}

\begin{enumerate}

\item
Veli Mäkinen, Gonzalo Navarro, Jouni Sirén, and Niko Välimäki: \\
\textbf{Storage and Retrieval of Highly Repetitive Sequence Collections}. \\
Journal of Computational Biology 17(3):281--308, 2010. \\
Preliminary versions in SPIRE 2008 and RECOMB 2009.

\item
Jouni Sirén:
\textbf{Compressed Suffix Arrays for Massive Data}. \\
16th Symposium on String Processing and Information Retrieval \\
(SPIRE 2009),
LNCS 5721, pp.~63--74, Springer, 2009.

\item
Jouni Sirén:
\textbf{Sampled Longest Common Prefix Array}. \\
21st Annual Symposium on Combinatorial Pattern Matching \\
(CPM 2010),
LNCS 6129, pp.~227--237, Springer, 2010.

\item
Jouni Sirén, Niko Välimäki, and Veli Mäkinen:
\textbf{Indexing Finite Language Representation of Population Genotypes}. \\
11th Workshop on Algorithms in Bioinformatics (WABI 2011), \\
LNCS 6833, pp.~270--281, Springer, 2011.

\end{enumerate}

Implementations and data sets used in the experiments can be found at \url{http://www.cs.helsinki.fi/group/suds/rlcsa/} for Papers~I\nobreakdash--III, and at \url{http://www.cs.helsinki.fi/group/suds/gcsa/} for Paper~IV.

\renewcommand{\theenumi}{\arabic{enumi}.}
\renewcommand{\labelenumi}{\theenumi}

\tableofcontents


\mainmatter

\include{introduction}

\include{background}

\include{csa}

\include{rlcsa}

\include{construction}

\include{lcp}

\include{gcsa}

\include{discussion}


\bibliographystyle{plain}
\bibliography{thesis}

\include{notation}

\end{document}
