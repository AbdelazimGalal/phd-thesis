\chapter{Space-efficient CSA construction}\label{chapter:construction}

In this chapter, we investigate the direct construction of compressed suffix arrays, extending the results in Paper~II. We are mostly interested in algorithms whose space usage is dominated by the CSA itself, making it possible to build indexes for texts that are larger than memory size.

The standard way of constructing compressed suffix arrays is to build a suffix array first, and then compress it. There are many existing algorithms \cite{Puglisi2007}, with the best of them working in $O(n)$ time and requiring $2n$ bits of working space in addition to the text and the suffix array \cite{Nong2009}. Yet as a compressed suffix array usually requires less than $n$ bytes of memory \cite{Ferragina2009a}, and can take less than $n$ \emph{bits} with highly repetitive texts (see Section~\ref{sect:rlcsa experiments}), this approach limits the use of CSAs to much smaller texts than could be handled in the available memory.

Many of the suffix array construction algorithms can be adapted to construct the Burrows-Wheeler transform directly. This often replaces the $4n$ to $8n$-byte suffix array with a $n$-byte BWT, reducing memory usage considerably. Yet even the best algorithms \cite{Kaerkkaeinen2007,Okanohara2009} require the text or the BWT --- or both --- in memory, limiting the size of the texts that can be indexed. External memory algorithms for constructing the suffix array \cite{Dementiev2008a} and the Burrows-Wheeler transform \cite{Ferragina2012} exist, but they tend to be slow in practice. In principle, dynamic self-indexes (see Section~\ref{sect:dynamic indexes}) could be used for space-efficient CSA construction, but the implementations seen so far are both slower and require more memory than the alternatives.

Direct algorithms for compressed suffix array construction \cite{Hon2007,Na2007,Hon2009} are the best solution so far. We are especially interested in the algorithm of Hon \etal{Hon2007} that works in $O(n \log n)$ time and requires $\abs{\CSA} + O(n)$ bits of memory. The algorithm essentially uses a static index to simulate CSA construction by a dynamic index, inserting many suffixes in a single update. We describe two practical variants of this algorithm: one that is more space-efficient and another one that can be faster than the original. As the basic building block, we describe an algorithm for merging compressed suffix arrays.

A similar idea has been recently used for constructing the Burrows-Wheeler transform for a large collection of short texts in external memory \cite{Bauer2011}. Instead of inserting large blocks of text at once, the algorithm extends each text by a single character in each step. This way, the algorithm remains simple and has to maintain only a small amount of state information, making it fast and space-efficient in practice. On the other hand, if the texts are longer than a few hundred characters, the algorithm requires too many passes over the data to be useful.


\section{Merging Burrows-Wheeler transforms}\label{sect:merging}

\paragraph{Algorithm of Hon et al.}

The construction algorithm of Hon \etal{Hon2007} can be interpreted as updating the Burrows-Wheeler transform of a text. Assume that we have already constructed $\BWT$ for some text $T$, and we want to update it for $ST$, where $S$ is a sequence of length $l$. We call the suffixes of $ST$ starting in $S$ the \emph{long suffixes} of $ST$, and the rest of the suffixes \emph{short suffixes}.

\begin{definition}
Let $T$ and $T'$ be two texts. The \emph{rank array} $\RA[1,\abs{T'}]$ of text $T'$ relative to text $T$ is an array such that $\RA[i] = \mrank(T, T'[i,\abs{T'}])$. The rank array of a set of suffixes of text $T'$ relative to text $T$ is the corresponding subsequence of array $\RA$.
\end{definition}

The definition also generalizes for collections of texts.

Updating the BWT starts with computing the rank array of long suffixes of text $ST$ relative to text $T$. Backward searching can be used to compute the rank array in a similar way as in the update rule for dynamic compressed suffix arrays (see Section~\ref{sect:dynamic indexes}). A detailed algorithm can be found in Figure~\ref{fig:rank array}.

\begin{figure}
\begin{tabbing}
mm\=mm\=mm\= \kill
\> \textbf{function} $\operatorname{computeRanks}(\mrank(T,T), S, l)$ \\
\> \> $pos \leftarrow \mrank(T, T)$ \\
\> \> \textbf{for} $i \leftarrow l$ \textbf{to} $1$ \\
\> \> \> $pos \leftarrow C[S[i]] + \mrank_{S[i]}(\BWT, pos) + 1$ \\
\> \> \> $\RA[i] \leftarrow pos$ \\
\> \> \textbf{return} $\RA$
\end{tabbing}

\caption{Computing the rank array of long suffixes of text $ST$ relative to text $T$ by backward searching the Burrows-Wheeler transform of $T$.}\label{fig:rank array}
\end{figure}

In addition to determining the lexicographic ranks of long suffixes among short suffixes, we must also determine their ranks among themselves. Conceptually this is done by sorting the long suffixes by their first $l$ characters, breaking ties by using the suffix array of $T$. With both ranks, we can determine the lexicographic ranks of long suffixes among all suffixes.

\begin{lemma}[Fact 1 in \cite{Hon2007}]
The lexicographic rank of a long suffix $S'$ among all suffixes of $ST$ is the sum of its lexicographic ranks among long suffixes and among short suffixes.
\end{lemma}

At this point, we have the lexicographic ranks among long suffixes in suffix array order, and the ranks among short suffixes in text order. By sorting the rank array in increasing order, we get both ranks in suffix array order. This follows from the fact that $S_{1} < S_{2}$ implies $\mrank(T, S_{1}) \le \mrank(T, S_{2})$. Hence the lexicographic ranks of long suffixes among short suffixes must form a non-decreasing sequence, when put into suffix array order. The entire merging algorithm is as follows.

\begin{enumerate}

\item Determine the rank array $\RA$ by the algorithm in Figure~\ref{fig:rank array}. Sort it to get array $\RA'$, and update this array by rule $\RA'[i] \leftarrow \RA'[i] + i$ to get the lexicographic ranks of long suffixes among all suffixes.

\item Sort the long suffixes, and form $\BWT_{S}$ as the subsequence of $\BWT_{ST}$ corresponding to the long suffixes.

\item Update $\BWT_{T}[\mrank(T, T)] \leftarrow S[l]$, and then merge $\BWT_{S}$ and $\BWT_{T}$ to get $\BWT_{ST}$. The merging is done by inserting characters from $\BWT_{S}$ to positions marked in $\RA'$, filling the rest of the positions with characters from $\BWT_{T}$.

\end{enumerate}

\begin{lemma}[Lemma 10 in \cite{Hon2007}]
The above algorithm updates $\BWT_{T}$ to $\BWT_{ST}$ in $O(l \log n + n)$ time, requiring $4l \log n + n + o(n)$ bits of space in addition to $\BWT_{S}$ and $\BWT_{T}$.
\end{lemma}

\paragraph{Merging compressed suffix arrays.}

A simplified version of the above algorithm can be used to merge two compressed suffix arrays. Assume that we have compressed suffix arrays for two texts $T$ and $T'$, and we want to merge them to get a compressed suffix array for the collection $\mathcal{C} = \set{T, T'}$. We select $\CSA_{T}$ as the basic index, and update it to get $\CSA_{\mathcal{C}}$.

In step 1, we get the rank array by searching $\CSA_{T}$ for text $T'$. However, as we are inserting entire texts instead of extending existing texts, we start with $\RA[\abs{T'}] = 1$, as the end marker of $T'$ will come immediately after the end marker of $T$ in lexicographic order. Step 2 is not needed, as we already have $\CSA_{T'}$. Step 3 works as above, except that we are merging compressed BWTs instead of plain BWTs. If we merge the bit vectors of an index of the CSA family one at a time, we are forced to scan the array $\RA'$ at least $\sigma$ times. This can be avoided by merging all bit vectors simultaneously, using a buffer of $\Theta(\sigma)$ characters to avoid polling each of the bit vectors for the next \onebit\ too often.

\begin{lemma}\label{lemma:merging}
The above algorithm merges compressed suffix arrays $\CSA_{T}$ and $\CSA_{T'}$, where $\abs{T'} \le \abs{T}$, in $O(\abs{T'} \cdot (t_{B} + \log \abs{T'}) + \min(\abs{\CSA_{TT'}}, \abs{T}))$ time, where $t_{B}$ is the time required for one step of backward searching. Working space is $\abs{T'} \log \abs{TT'} + O(\sigma \log n)$ bits in addition to the CSAs and $T'$.
\end{lemma}

The lemma applies for indexes of both CSA and FMI families, as long as individual bit vectors can be merged in time relative to their compressed size, and a sequential scan of a bit vector can be done in $O(n_{1})$ time. It generalizes immediately to merging compressed suffix arrays of collections of sequences.

We can also output the rank array directly in suffix array order, avoiding the $O(\abs{T'} \log \abs{T'})$ term in the time bound, if we backward search $\CSA_{T'}$ simultaneously. This allows us to store the array $\RA'$ as a bit vector of length $\abs{TT'}$, which can be much less than the $\abs{T'} \log \abs{TT'}$ bits of a plain array, if the texts are of similar size. We do not even need the text $T'$, as it can be efficiently extracted from $\CSA_{T'}$ (in blocks of $d$ characters in the CSA family, as extraction proceeds in forward direction). In practice, none of these optimizations are very useful, as backward searching is much more expensive than integer sorting.


\section{Construction algorithm}\label{sect:construction}

The merging algorithm can be used as the basic building block of a space-efficient CSA construction algorithm. Assume that we have a large collection of texts $\mathcal{C}$ with total length $N$. The algorithm is as follows, with $\CSA_{i}$ denoting the compressed suffix array of collection $\mathcal{C}_{i}$.
\begin{enumerate}
\item Split the collection into $m$ smaller collections $\mathcal{C}_{1}, \dotsc, \mathcal{C}_{m}$ of size $N/m$.
\item Build $\CSA = \CSA_{1}$, and use it as a basis for the final index.
\item For $i = 2, \dotsc, m$, build $\CSA_{i}$ and merge it with $\CSA$ to get the new $\CSA$.
\end{enumerate}

Note that if there are $r$ sequences in the union of collections $\mathcal{C}_{1}, \dotsc, \mathcal{C}_{i}$, the rank array of collection $\mathcal{C}_{i+1}$ must have value $r$ for each end marker in the collection.

\begin{theorem}
Let $\mathcal{C}$ be a collection of texts with total length $N$ that can be split into $m$ subcollections of size $N/m$. We can use the merging algorithm to construct a compressed suffix array for $\mathcal{C}$ in $O(N + m \cdot \min(\abs{\CSA}, N))$ time using $\abs{\CSA} + \max_{i}(\abs{\CSA_{i}}) + O((N/m + \sigma) \log N)$ bits of space, where $\sigma$ is the size of the alphabet and $\CSA_{i}$ is a CSA for the $i$th subcollection.
\end{theorem}

\begin{proof}
We assume that the CSA is based on bit vectors that support \rank\ and \select\ in $O(1)$ time. By using backward searching on $\CSA_{i}$ to output the rank array directly in suffix array order, we can do all merges within the given time and space bounds. The result follows by using any linear-time suffix array construction algorithm for building the partial indexes $\CSA_{i}$.
\end{proof}

The algorithm can be efficiently parallelized on a single machine. For building the partial indexes, we can either use a parallel suffix array construction algorithm or, if memory allows, index multiple subcollections in parallel. Backward searching can be parallelized, as it does not change the state of the index. Parallel sorting is a well-researched topic, so it does not matter, whether we construct the rank array in text order or in suffix array order. Finally, merging can be parallelized by either merging multiple bit vectors simultaneously, or by dividing a bit vector into multiple parts for merging. If the final CSA is small enough to fit into the memory of a single system, we can also use a computer cluster for construction.


\section{Indexing a single sequence}\label{sect:single sequence}

With practical implementation choices, the algorithm in Section~\ref{sect:construction} uses roughly $(2N/m) \log N$ bits of working space to construct a compressed suffix array for a collection of total size $N$ in $m$ parts, while the algorithm of Hon \etal{Hon2007} uses roughly $(4N/m) \log N + N$ bits. As the algorithms are otherwise almost the same, this represents a significant improvement in space usage without any similar penalty in performance. On the other hand, the collection must be partitioned at sequence boundaries, while the algorithm of Hon et~al.\ can use arbitrary partitioning. In this section, we show how this limitation can be lifted by using $(3N/m) \log N$ bits of working space, with the possibility of making the algorithm faster in practice.

As noted in Section~\ref{sect:merging}, $S_{1} < S_{2}$ implies $\mrank(T, S_{1}) \le \mrank(T, S_{2})$ for any text $T$ and any sequences $S_{1}$ and $S_{2}$. In particular, this means that $T'[i,\abs{T'}] < T'[j,\abs{T'}]$ implies $\RA[i] \le \RA[j]$ in the merging algorithm. Additionally, $T'[i] < T'[j]$ implies $T'[i] + \RA[i] < T'[j] + \RA[j]$. This means that sequence $T' + \RA$ (where $(T'+\RA)[i] = T'[i] + \RA[i]$) has the same suffix array as text $T'$.

\begin{lemma}\label{lemma:rank array}
Let $T$ and $T'$ be two texts. Then $T' + \RA$ has the same suffix array as text $T'$, where $\RA$ is the rank array of text $T'$ relative to text $T$.
\end{lemma}

If text $T$ is much longer than text $T'$, most elements in the rank array are likely to be unique. Hence it should be faster to build a suffix array for the rank array than for the text itself. This gives us the following algorithm.
\begin{enumerate}
\item Split the collection into $m$ smaller collections $\mathcal{C}_{1}, \dotsc, \mathcal{C}_{m}$ of size $N/m$.
\item Build $\CSA = \CSA_{1}$, and use it as a basis for the final index.
\item For $i = 2, \dotsc, m$, determine the rank array $\RA$ of collection $\mathcal{C}_{i}$ relative to the union of all previous collections $\mathcal{C}'$. Build a suffix array of $\mathcal{C}_{i} + \RA$, use it to build $\CSA_{i}$, and merge $\CSA_{i}$ with $\CSA$ to get the new $\CSA$.
\end{enumerate}

We may have to split a text $T = S T'$ into two collections, so that $T' \in \mathcal{C}_{i}$ and $S \in \mathcal{C}_{i+1}$. In this case, we append an end marker to string $S$, and put $x = \mrank(\mathcal{C}',T')$ in the corresponding position in the rank array. As the end marker must be unique to get the correct suffix array, we increment the rank array by $1$ for all other positions $i$, where $\RA[i] \ge x$. Furthermore, if collection $\mathcal{C}'$ contains $r$ texts, and there are $r'$ texts with regular end markers in collection $\mathcal{C}_{i+1}$, we reserve ranks $r, \dots r+r'-1$ for the end markers to get the correct ordering between them, and increment all other values by $r'-1$. Note that we have to remove the position corresponding to the end marker of string $S$ from the suffix array before constructing $\CSA_{i+1}$, as the end marker is not included in the original collection. Note that all changes to the rank array must be reversed, before it can be used in merging.

\begin{theorem}
Let $\mathcal{C}$ be a collection of texts with total length $N$, and let $m > 0$ be an integer. We can use the merging algorithm to construct a compressed suffix array for $\mathcal{C}$ in $O(N + m \cdot \min(\abs{\CSA}, N))$ time using $\abs{\CSA} + \max_{i}(\abs{\CSA_{i}}) + O((N/m + \sigma) \log N)$ bits of space, where $\sigma$ is the size of the alphabet and $\CSA_{i}$ is a CSA for the $i$th subcollection.
\end{theorem}

The working space is now roughly $(3N/m) \log N$ bits, as suffix array construction algorithms generally require $(2N/m) \log N$ bits of writable space with large alphabets, and the rank array must be kept intact during construction.


\section{Implementation}\label{sect:construction implementation}

Two variants of the construction algorithm are included in the implementation of RLCSA (see Chapter~\ref{chapter:rlcsa}). Written in C++, the principal goal of the implementation is to allow indexing text collections that are too large to fit into memory. The implementation has been parallelized by using \emph{OpenMP} and either \emph{MCSTL}\footnote{\url{http://algo2.iti.kit.edu/singler/mcstl/}} or the version of MCSTL integrated into GCC, the \emph{libstdc++ parallel mode}. Both algorithms assume that the collection is stored on disk as a set of $m$ files, each of them less than $4$ gigabytes in size.

First of the algorithms, \emph{Merge}, is an implementation of the algorithm in Section~\ref{sect:construction}. It first builds RLCSAs for all of the subcollections, using a parallelized prefix-doubling algorithm (see below) for the task, and stores them on disk. After all partial indexes have been built, the algorithm starts merging them. Merging has also been parallelized, assuming that the current subcollection consists of multiple texts, so that multiple threads can be used to construct the rank array. The merging phase requires roughly $9n$ bytes of memory in addition to the two RLCSAs, where $n = N/m$ is the size of a subcollection. This includes $8n$ bytes for the rank array and $n$ bytes for the collection. In practice, working space can be significantly more than that, as in-place merging of bit vectors has not been implemented.

The second algorithm, \emph{Fast}, is the algorithm from Section~\ref{sect:single sequence}, except that splitting a text into two subcollections has not been implemented. It processes the subcollections one at a time, using the rank array to build a RLCSA, before merging it with the existing index. This variant uses $25n$ to $29n$ bytes of working space, where the extra $16n$ to $20n$ bytes comes from the suffix array construction algorithm.

Both algorithms use a parallelized \emph{prefix-doubling} algorithm to build the partial indexes. Prefix-doubling-based algorithms are useful for constructing suffix arrays for collections, as we can easily afford having different lexicographic values for the end markers of different sequences. A prefix-doubling algorithm maintains an invariant that array $\SA_{k}$ contains the suffixes in lexicographic order, and array $\RA_{k}$ contains the lexicographic ranks of the suffixes in text order, when the ordering is based on $k$\nobreakdash-character prefixes of each suffix. From these arrays, $\SA_{2k}$ can be determined by sorting $\SA_{k}$ with $(\RA_{k}[\SA_{k}[i]], \RA_{k}[\SA_{k}[i]+k])$ as the sort key for $\SA_{k}[i]$. From $\SA_{2k}$, it is then easy to determine $\RA_{2k}$ in linear time. If sorting is also done in linear time, the prefix-doubling algorithm uses $O(n \log n)$ time for a collection of size $n$.

\newpage The algorithm has been influenced by the suffix array construction algorithm of Larsson and Sadakane \cite{Larsson2007}. If suffix $\SA_{k}[i]$ has already been sorted, we have $\RA_{k}[i] = \RA_{2k}[i]$ and $\SA_{k}[i] = \SA_{2k}[i]$. Hence we have to handle only unsorted ranges in subsequent iterations. To make parallelization easier, we store the unsorted ranges explicitly as pairs of $32$\nobreakdash-bit integers. In the worst case, there can be almost $n/2$ unsorted ranges in both $\SA_{k}$ and $\SA_{2k}$, requiring up to $4n$ bytes of space. In practice, the ranges take at most $n$ bytes of space.

As the first part of the sort key is equal for all suffixes in an unsorted range, we only have to use $\RA_{k}[\SA_{k}[i]+k]$ as the sort key for $\SA_{k}[i]$. To avoid cache misses during sorting, we sort pairs $(\SA_{k}[i], \RA_{k}[\SA_{k}[i]+k])$ of two $32$\nobreakdash-bit integers, instead of retrieving the sort key indirectly. This increases the space usage of the algorithm by $4n$ bytes to a total of $12n$ to $16n$ bytes. Initially, we use the parallel quicksort from MCSTL to sort pairs $(i, T[i,i+1])$ or $(i,T[i])$, depending on whether we can pack two characters into a single $32$\nobreakdash-bit integer. Later, we divide the unsorted ranges between a number of threads, and use the standard sequential sorting algorithm from STL to sort each of the ranges.

The suffix array construction algorithm used in Fast differs from the basic version above. As we are building the suffix array for the rank array instead of the collection, we have to use $64$\nobreakdash-bit sort keys in the initial sorting, and cannot pack two adjacent characters into the key. On the other hand, as the elements of $\RA_{k}$ are $32$\nobreakdash-bit integers, we can pack both $\RA_{k}[\SA_{k}[i]+k]$ and $\RA_{k}[\SA_{k}[i]+2k]$ into the sort key of $\SA_{k}[i]$, and obtain $\SA_{3k}$ instead of $\SA_{2k}$. This prefix-tripling algorithm uses $16n$ to $20n$ bytes of memory, and is usually somewhat faster than the prefix-doubling variant.


\section{Experiments}

To compare the performance of Merge and Fast, we used both algorithms to build RLCSA for two data sets from Paper~II. The first of them, \emph{fiwiki}, is the Finnish language Wikipedia with full version history ($42.03$ gigabytes), while the other, \emph{enwiki}, is a snapshot of the English language Wikipedia ($41.46$ gigabytes). Of the two data sets, fiwiki is a highly repetitive collection. The construction was done on the same system as in Section~\ref{sect:rlcsa experiments}, using 8 parallel threads.

The only other CSA construction algorithm for collections that are too large to fit into memory is the algorithm of Hon \etal{Hon2007} that is essentially an earlier variant of Merge. Some implementations \cite{Lam2008,Li2009} of the algorithm exist, but they can only be used for constructing uncompressed BWT for texts over $2$\nobreakdash-bit alphabets such as DNA sequences. As the algorithms are so similar to each other, any performance differences would most likely be due to implementation choices.

Another way to construct CSAs for collections larger than the main memory is to use an external memory suffix array or BWT construction algorithm. The fastest known general-purpose algorithm is the \emph{bwte} of Ferragina \etal{Ferragina2012}. Distantly related to the algorithm of Hon \etal{Hon2007}, bwte builds an index for the long suffixes, streams the already indexed part of text to determine the \emph{gap array}, and uses the gap array to merge the new index with the existing BWT. The gap array, closely related to the rank array, stores the number of short suffixes falling between two lexicographically adjacent long suffixes. If a collection of size $N$ is indexed in $m$ passes, bwte takes $O(mN)$ time, streams $O(mN \log \sigma)$ bits of data, and requires $O((N/m) \log (N/m))$ bits of working space. As our test environment uses network storage with relatively low transfer rates, it was not reasonable to use it for testing external memory algorithms. Instead, we used a system with a quad-core 2.93 GHz Intel Core i7\nobreakdash-870 processor running OS~X 10.6.8 with bwte. This system had $16$ gigabytes of memory and a solid-state drive.

We split both data sets into $400$\nobreakdash-megabyte subcollections for Merge and Fast, and also used $800$\nobreakdash-megabyte subcollections with Merge. We built RLCSA with default parameters $b = 32$ bytes and $d = 128$. The final index sizes were $14.33$ GB for enwiki and $4.42$ GB for fiwiki. For bwte, we used $1.5$\nobreakdash-gigabyte subcollections, resulting in $28$ (enwiki) and $29$ (fiwiki) passes over the input collection.

In the fiwiki collection, different versions of the same document are stored consecutively. This is almost the worst possible ordering for Fast. If a number of lexicographically adjacent suffixes belong to the same subcollection, they will have the same values in the rank array, and sorting them probably requires many iterations. To test the effect of document ordering, we sorted the sequences in fiwiki by their timestamps. We then compared Merge using $400$ and $800$\nobreakdash-megabyte and $1.5$\nobreakdash-gigabyte subcollections with Fast using $400$\nobreakdash-megabyte subcollections on the new collection \emph{fiwiki-sorted}.

\begin{table}
\centering
\renewcommand{\tabcolsep}{.1cm}
\begin{tabular}{lcccccccccc}
\hline\noalign{\smallskip}
\textbf{Algorithm} & & \textbf{Time} & \textbf{Space} & \textbf{Speed} & & \textbf{Build} & \textbf{Rank} & \textbf{Sort} & \textbf{Merge} & \textbf{I/O} \\

\noalign{\smallskip}
\hline
\noalign{\smallskip}
\multicolumn{10}{l}{\textbf{enwiki}} \\
Merge-400  & & 10.3 & 24.5 & 1.14 & & 3.91 & 1.52 & 0.94 & 3.28 & 0.68 \\
Merge-800  & &  8.6 & 27.0 & 1.36 & & 3.34 & 1.50 & 0.94 & 2.14 & 0.71 \\
Fast-400   & &  8.9 & 30.0 & 1.32 & & 3.24 & 1.51 & 0.92 & 2.97 & 0.28 \\
bwte-1536  & & 84.3 & 12.0 & 0.14 & & --   & --   & --   & --   & --   \\
\noalign{\smallskip}
\multicolumn{10}{l}{\textbf{fiwiki}} \\
Merge-400  & & 11.8 & 11.6 & 1.01 & & 6.96 & 1.38 & 0.87 & 2.23 & 0.37 \\
Merge-800  & & 10.1 & 14.0 & 1.18 & & 5.68 & 1.34 & 0.88 & 1.64 & 0.57 \\
Fast-400   & & 10.5 & 19.4 & 1.14 & & 6.27 & 1.37 & 0.86 & 1.73 & 0.27 \\
bwte-1536  & & 72.9 & 12.0 & 0.16 & & --   & --   & --   & --   & --   \\
\noalign{\smallskip}
\multicolumn{10}{l}{\textbf{fiwiki-sorted}} \\
Merge-400  & & 12.6 & 11.5 & 0.95 & & 7.48 & 1.25 & 0.94 & 2.36 & 0.60 \\
Merge-800  & & 11.2 & 15.0 & 1.07 & & 6.38 & 1.20 & 0.96 & 2.10 & 0.52 \\ 
Merge-1536 & & 11.3 & 22.9 & 1.06 & & 7.08 & 1.18 & 0.95 & 1.66 & 0.45 \\
Fast-400   & & 10.1 & 19.7 & 1.18 & & 5.51 & 1.25 & 0.94 & 2.33 & 0.11 \\
\noalign{\smallskip}
\hline
\end{tabular}

\caption{Indexing two $41$ to $42$\nobreakdash-gigabyte collections. Construction time in hours, memory usage in gigabytes, and construction speed in megabytes per second. For Merge and Fast, the numbers also include a breakdown of time usage between partial index construction (Build), rank array construction (Rank), rank array sorting (Sort), index merging (Merge), and I/O and other overhead (I/O). The number in algorithm name indicates subcollection size in megabytes.}\label{table:construction}
\end{table}

Construction times and memory requirements can be seen in Table~\ref{table:construction}. Note that while the results for bwte include just BWT construction, building RLCSA would not increase construction time significantly. In general, Fast is faster than Merge with the same subcollection size, while Merge offers better time/space trade-offs. However, when the sequences have been sorted by their timestamps, Fast becomes faster than Merge with the same amount of memory, as it can build the partial indexes much faster.
% See Chapter~\ref{chapter:conclusions} for discussion on other ways of using the rank array to speed up partial index construction.

\newpage Both Merge and Fast are much faster than bwte. While bwte is an external memory algorithm, its performance is constrained by CPU speed in practice. Most of the time is taken by the construction of the gap arrays. This requires backward searching for a volume of data equal to roughly $m/2$ times the size of the collection --- more than $500$ gigabytes in these experiments. As backward searching is easy to parallelize, minor modifications should make bwte more competitive on current hardware.

Even though the prefix-doubling algorithm has superlinear time complexity, increasing subcollection size from $400$ megabytes to $800$ megabytes decreases the time required for constructing the partial indexes. A probable explanation is that while the total amount of work increases with block size, the algorithm parallelizes better when sorting larger sets of suffixes. Merging also takes less time with larger block sizes, as fewer merges are required. Still, the effect of subcollection size on running time remains small.
