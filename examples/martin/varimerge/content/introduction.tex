%\section{Introduction}A lab method known as Pulse Flow Gel Electrophoresis (PFGE)  has been traditionally used to capture identifying characteristics of the pathogen which are then compared to a database known as PulseNet to narrow down its possible source in outbreak investigation~\cite{sandt2006key,boxrud2010role}. 


%Every year, approximately one million people suffer from foodborne illness attributed to Salmonella according to the US Center for Disease Control (CDC).  When an outbreak occurs there is a desire to identify the source in order to intervene in the outbreak.  
 In recent years, there has been an initiative to move toward using whole genome sequencing to accurately identify and track foodborne pathogens (e.g. antibiotic resistant bacteria)~\cite{carleton2016whole}. This led to the existence of GenomeTrakr, which is a large public effort to use genome sequencing for surveillance and detection of outbreaks of foodborne illnesses. Currently, the GenomeTrakr effort includes over 50,000 samples, spanning several species available through this initiative---a number that continues to rise as datasets are continually added \cite{genometrakr}.  Unfortunately, methods to analyze this and other datasets are limited due to their size.   Existing methods for using this WGS data frequently focus on a method known as Multi Locus Sequence Typing (MLST)~\cite{pettengill2016}, which aligns reads to genes from a reference genome.  These alignments identify sets of alleles and thus, are limited to capturing genetic variations that are both shorter than the length of reads and only those variations that align to a reference genome or gene set~\cite{maiden2013mlst}.  Thus, variations that are longer than read length or that exist in the population but not the reference genome go undetected.

Given the limitations of existing methods, we would like to apply advanced methods for identifying variants---such as Cortex~\cite{ICTFM12} and $\vari$ \cite{vari}---which are able to detect complex variants without a reference. These methods use a modification of the de Bruijn graph that is referred to as the colored de Bruijn graph.   We define the {\em de Bruijn graph} constructively as follows: a directed edge is created for every unique $k$-length subsequence ({\em k-mer}) in the data and an origin and destination vertex are labeled with the prefix and suffix of that $k$-mer, and after all edges have been created and labeled, the vertices that have the same label are glued into a single vertex.  We create a {\em colored de Bruijn graph} by adding a set of colors (or labels) to each edge (and/or vertex) indicating which sample(s) contain the respective $k$-mer (and/or $(k - 1)$-mer).  Iqbal et al.~\cite{ICTFM12} were the first to present the concept of the colored de Bruijn graph and demonstrate how it can be traversed to identify genetic variation between samples.  

A bottleneck in applying Cortex to large datasets is the amount of memory required to build and store the colored de Bruijn graph.   $\vari$~\cite{vari} and Rainbowfish~\cite{rainbowfish} sought to overcome this limitation by improving the storage efficiency of the graph.  However, even though these methods store the colored de Bruijn graph in a memory-efficient manner, they are still unable to scale in a manner that is necessary for massive datasets such as GenomeTrakr.  The limiting factor for these methods  lies in their construction; Both $\vari$~\cite{vari} and Rainbowfish~\cite{rainbowfish} must manipulate the (uncompressed) data in external memory in order to build the graph in a memory-efficient manner; making  external memory use the bottleneck.  Moreover, this increases the construction time of the graph as external memory use is slower than that of RAM.  Thus, one way to improve the scalability and enable researchers to construct the colored de Bruijn graph on  massive datasets is to use a divide-and-conquer approach: divide the data into smaller partitions, construct the colored de Bruijn graph for each partition, and merge the (smaller) colored de Bruijn graphs until a single graph remains.  While partitioning the data and building small graphs is possible, there exists no method to succinctly merge (colored) de Bruijn graphs.


\paragraph{Our contributions.}  Thus, we present $\ours$ that enables construction of massive colored de Bruijn graph through a process of partitioning the data into smaller sets, building the colored de Bruijn graph in a memory-efficient manner for each parition, and merging colored de Bruijn graphs. Each of the colored de Bruijn graphs is stored using the FM-index in the same manner as $\vari$~\cite{vari}.  We review this representation in Section 3 of the paper~\cite{BOSS}.  Thus, the algorithmic challenge that we tackle is merging the graphs in a manner that keeps them in their compressed format throughout the merging process---rather than decompressing, merging and compressing which would be impractical with respect to disk and memory usage.  



%This is in contrast to the existing construction method which requires external memory in order to manipulate the uncompressed data.  By working with compressed data directly, less working space is required which also means all computation can be performed in RAM. Using this construction method opens the door to using the colored de Bruijn graph for complex variant detection among the largest current population genetics studies including GenomeTrakr, 10,000 vertebrates~\cite{hayden200910}, and the {\em iK5} project~\cite{Robinson:2011}, 
%Hence, we demonstrate that $\ours$ takes $O(m \max(k, t))$-time, where $m$ is the edges, $k$ is the $k$-mer length, and $t$ is the number of colors.
%We develop an efficient algorithm for  merging succinct colored de Bruijn graphs, and demonstrate its efficiency in producing a massive colored de Bruijn graph from a collection of smaller ones.  In particular, 

By using $\ours$, we build a colored de Bruijn graph for 16,000 strains of Salmonella that were collected and housed at NCBI as part of the GenomeTrakr database.  This represents the first and only large-scale assembly based analysis of the GenomeTrakr data~\cite{pettengill2016} and to the best of our knowledge, the largest dataset for which the (colored) de Bruijn graph has been constructed.  The most recent unrelated large-scale construction is due to  Holley et al.~\cite{holley2015bloom}, which presents a de Bruijn graph construction for 473 clinical isolates of {\em Pseudomonas aeruginosa} (NCBI BioProject PRJEB5438).  Our GenomeTrakr dataset is over 30 times this size of this latter one.   The construction of this colored de Bruijn graph required a total of 254 G of RAM, 2.34 TB of external memory, and less than 72 hours of CPU time.  $\vari$ and Rainbowfish could--at least, in theory--construct the graph for this large of a dataset but would require over 10 TB of disk space and more computing time.  Moreover, our results that compare $\ours$ with Bloom Filter Trie demonstrate that it would require significantly more memory to construct and store and the colored de Bruijn graph on this dataset.  

Therefore, $\ours$ is superior with respect to the memory and disk usage.  It is more memory-efficient that Bloom Filter Trie.   Thus, it has the memory-efficiency of competing succinct representations (e.g., $\vari$ and Rainbowfish) but it removes the extensive disk constraints these method have, making $\ours$ practical for massive datasets.  


%Our results on Bloom Filter Trie demonstrate that it would require significant more memory.  Hence, $$ 

%Furthermore,   We show $\ours$ can reduce total construction memory footprint for an 8,000 Salmonella strain graph from 4.9 TB to 1.6 TB and running time from 36 hours to 26 hours by means of building and merging two 4,000 strain graphs. We also show the benefits of merging as a means of incremental construction by adding one strain to a graph with 4,000 strains in only 49 minutes and 5 GB of total memory. This compares favorably with the 9 hours and 1.1 TB of total memory such a 4,001 strain graph would take to construct from scratch. We also validate our method by showing a graph built by merging two subgraphs is bitwise identical in representation to a graph built for the entire set of strains with $\vari$.  

%as well as the Sequence Bloom Trees index structure by Solomon~{\it et al}~\cite{solomon2015large}.

 

\section{Related Work}


Space-efficient representations of de Bruijn graphs have been heavily researched in recent years. One of the first approaches was introduced with the creation of the ABySS assembler, which stores the graph as a distributed hash table~\cite{Simpson:2009}.  In 2011, Conway and Bromage~\cite{conway} reduced these space requirements  by using a sparse bitvector (by Okanohara and Sadakane~\cite{bitvector}) to represent the $k$-mers, and used rank and select operations (to be described shortly) to traverse it.  Minia~\cite{wabi} uses a Bloom filter to store edges, which requires the graph to be traversed by generating all possible outgoing edges at each node and testing their membership in the Bloom filter. Bowe, Onodera, Sadakane and Shibuya~\cite{BOSS} developed a succinct data structure based on the Burrows-Wheeler transform  (BWT)~\cite{bw1994}.  This data structure is discussed in more detail in the next section.  This data structure of Bowe et al.~\cite{BOSS} is combined with ideas from IDBA-UD~\cite{idbaud} in a metagenomics assembler called MEGAHIT~\cite{megahit}.   Chikhi {et al.}~\cite{paul} implemented the de Bruijn graph using an FM-index and {\em minimizers}.

More recently, methods have been developed to store de Bruijn graphs for a population which entails an additional space burden in tracking which samples contribute to graph elements. Holley et. al.~\cite{holley2015bloom} introduced the Bloom Filter Trie, which is another succinct data structure for the colored de Bruijn graph.  SplitMEM~\cite{splitmem} is a related algorithm that creates a colored de Bruijn graph from a set of suffix trees representing the other genomes.  Lastly, $\vari$~\cite{vari} and Rainbowfish~\cite{rainbowfish} are both memory-efficient data structures for storing the colored de Bruijn graph.  Both are discussed later in this paper.

The closest related work to that proposed here concerns other reduced-memory colored de Bruijn graphs with efficient construction. SplitMEM~\cite{splitmem} uses suffix trees to directly construct the compacted de Bruijn graph, where non-branching paths become single nodes.  Here, we use the term {\em compacted} to distinguish this approach from data compression techniques underlying succinct data structures.  Baier et al.~\cite{baier2015graphical} improved on this method with two alternative construction methods, using the compressed suffix tree and using BWT. TwoPaCo~\cite{minkin2016twopaco} uses a bloom filter to represent the ordinary de Bruijn graph and then constructs the compacted de Bruijn graph from the bloom filter encoded one.    Bloom filter tries, proposed by Holley  et al.~\cite{holley2015bloom} encode frequently occurring sets of colors separate from the graph and stores a reference to the set if the reference takes fewer bits than the set itself.   This data structure allows incremental updates of the underlying graph.  Rainbowfish~\cite{rainbowfish} also stores distinct sets of colors in a table and uses Huffman-like variable length bit patterns to reference color sets from each edge in the succinct de Bruijn graph.  Both the Bloom filter trie method and Rainbowfish are able to collapse redundant color sets across the entire graph to a single instance instead of just along non-branching paths in the compacted graph methods.  

Although Rainbowfish can store the colored de Bruijn graph in less memory than $\vari$, it uses  $\vari$ as a preprocessing step in its construction, so it is still limited to  $\vari$'s construction capacity. 

Lastly, two other approaches are worthy of note because they merge the BWT of a set of strings.  BWT-Merge by Sir{\'e}n~\cite{siren2016burrows} is related to our work since the data structure we construct and store is similar to BWT.  BWT-Merge merges two strings stored using BWT by using a reverse trie of one BWT to generate queries that are then located in the other BWT using FM-Index backward search.  The reverse trie allows the common suffixes across multiple merge elements to share the results of a single backward search step. Thus, BWT-Merge finds the final rank of each full suffix completely, one suffix at a time.   Finally, Holt and McMillan developed MSBWT~\cite{holt2014merging} which merges the BWTs of multiple strings in a method similar to our own except applied to strings instead of graphs.


